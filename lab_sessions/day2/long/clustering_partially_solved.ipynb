{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "In this module, we will learn about clustering in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as skdat\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering\n",
    "\n",
    "As discussed in the talk, K-means is an effective clustering algorithm that is widely used. In this lab, you will implement K-means and explore its strengths and limitations.\n",
    "\n",
    "Here is the pseudocode for K-means:<br/>\n",
    "<ol>\n",
    "    <li>randomly initialize $\\mu_k, \\mathrm{\\;for\\;} k=1,\\dots,K$</li>\n",
    "    <li>while $\\mu$ not converged:</li>\n",
    "    <ol>\n",
    "        <li>assign data point n to nearest cluster: $r_{n} \\leftarrow \\arg \\min_k ||x_n - \\mu_k ||^2, \\mathrm{\\;for\\;} n=1,\\dots,N$</li>\n",
    "        <li>count number of data points assigned to cluster $k$, $N_k \\leftarrow \\sum_{n=1}^N r_{nk}, \\mathrm{\\;for\\;} k=1,\\dots,K$</li>\n",
    "        <li>update cluster centers: $\\mu_k \\leftarrow \\frac{1}{N_k} \\sum_{n=1}^N x_n r_{nk}, \\mathrm{\\;for\\;} k=1,\\dots,K$</li>\n",
    "    </ol>\n",
    "</ol>   \n",
    "Recall that $r_{nk}$ is a binary variable indicating whether data point $n$ is assigned to cluster $k$ and that $\\mu_k$ is the center for cluster $k$. Note that $\\mu_k$ could be a scalar or a vector; its dimensionality matches that of the data $x_{1:N}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Given the above pseudocode for K-means, complete the implementation below.\n",
    "\n",
    "Guidance: your answer will likely include a main *while* loop (one for each outer iteration of K-means) and two *for* loops (one stepping through the data and another stepping through the clusters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeans(X, K, eps=1e-5, max_iterations=200):\n",
    "    \"\"\"\n",
    "        arguments:\n",
    "            X: a (N,D) numpy array of observed data\n",
    "            K: integer indicating number of clusters\n",
    "            eps (optional): real threshold for change in mu for deciding when to stop\n",
    "            max_iterations (optional): max num of iterations, regardless of eps threshold\n",
    "        returns:\n",
    "            mu: a (K,D) numpy array of cluster means after k-means converged\n",
    "            R: a (N,K) numpy array of binary cluster assignments\n",
    "    \"\"\"\n",
    "    \n",
    "    #todo: put your code here\n",
    "    (N,D) = X.shape\n",
    "    np.random.seed(100)\n",
    "    rand_n = np.random.choice(range(N),size=K)\n",
    "    mu = X[rand_n,:]\n",
    "    prev_mu = np.inf #always do the first iteration\n",
    "    R = np.zeros((N,K)) #this will be written over before first read\n",
    "    it = 0\n",
    "    while np.abs(mu-prev_mu).sum() >= eps and it<max_iterations:\n",
    "        #store previous value of mu\n",
    "        prev_mu = mu.copy()\n",
    "        #A. update cluster assignments according to nearest cluster\n",
    "        for n in range(N):\n",
    "            d = np.array([np.linalg.norm(X[n,:] - mu[k,:]) for k in range(K)])\n",
    "            R[n,:] = 0.\n",
    "            R[n,d.argmin()] = 1.\n",
    "        #B. calculate cluster sizes\n",
    "        Nk = R.sum(axis=0) + 1e-9 #add epsilon to avoid divide by zero errors\n",
    "        #C. update cluster centers\n",
    "        mu = np.dot(R.T, X) / Nk[:,np.newaxis] #results in a (K,D) matrix\n",
    "        it += 1\n",
    "        #print('cluster centers',mu)\n",
    "        #print('cluster assignments',R)    \n",
    "    \n",
    "    return mu, R\n",
    "\n",
    "#apply to some toy data generated by sklearn package:\n",
    "N,D,K = 100, 2, 3\n",
    "X, true_class = skdat.make_blobs(n_samples=N, n_features=D, centers=K, random_state=0)\n",
    "mu, R = kmeans(X,K)\n",
    "print('cluster centers',mu)\n",
    "print('cluster assignments',R.argmax(axis=1))\n",
    "print('true assignments',true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "def plot_clusters_2D(X,R,mu,separate=False,titles=None):\n",
    "    colors = ['r', 'g', 'b']\n",
    "    A = R.argmax(axis=1) #calculate most likely cluster assignment\n",
    "    for k in range(K):\n",
    "        nsk, = np.where(A==k) #select data points based on assignment\n",
    "        c = colors[k % len(colors)] #choose colour from list\n",
    "        plt.scatter(X[nsk,0], X[nsk,1], marker='x', color=c)\n",
    "        plt.scatter(mu[k,0],mu[k,1],color=c)\n",
    "        if titles is not None: plt.title(titles[k])\n",
    "        if separate and k<K-1: plt.figure()\n",
    "plot_clusters_2D(X,R,mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: \n",
    "How does your implementation scale in the number of data points $N$ and the number of clusters $K$?\n",
    "\n",
    "#### Answer:\n",
    "[write here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label switching\n",
    "Notice the discovered cluster assignments from K-means are different from the known assignments used in data generation, even though the means are quite close. This phenonmenon is known as \"label switching\" and results from the fact that the underlying model is symmetric with respect to cluster assignments (i.e., data points belong to the same cluster they are assigned to even if we switch the cluster id's of all the assignments). \n",
    "\n",
    "#### Bonus Task (optional)\n",
    "Write a method to calculate how well the cluster assignments discovered by K-means matches those of the generated data regardless of label switching. Use an error of 0 if they match and an error of 1 if they do not, then find the average over all data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "As discussed in the talk, there are several limitations of K-means. One of them is that it is sensitive to outliers. \n",
    "\n",
    "#### Question:\n",
    "Why is K-means sensitive to outliers (write below)?\n",
    "#### Answer:\n",
    "[here]\n",
    "\n",
    "The first step in this task is to add outliers to the above 2D toy data set. Set the variable outliers below to include outliers in the context of X and add it to the X dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outliers = np.array([\n",
    "                [x_11,x_12],\n",
    "                [x_21,x_22],\n",
    "                [x_31,x_32]\n",
    "                 ])\n",
    "X_outlier = np.vstack((X, outliers))\n",
    "mu1, R1 = kmeans(X_outlier,K)\n",
    "plot_clusters_2D(X_outlier,R1,mu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply your *kmeans* function to X_outliers and visualize the results. Specifically, color-code each data point $n$ by its assignment $r_{nk}$, giving each cluster a different color. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering New York City collisions data\n",
    "\n",
    "To end this lab session, we will apply the clustering methods you just implemented to a subset of the New York City collisions data set. The data set is the location of traffic collisions in New York City between June 1st 2016 and June 8th 2016. The data was obtained from https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95/data\n",
    "\n",
    "We will use the `Pandas` library to simply load a CSV (comma-separated values) file of the data and display a summary (the first and last several rows) of the whole data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = './data/nyc_collisions_01june_08june_2016.csv'\n",
    "collisions_table = pd.read_csv(data_path)\n",
    "collisions_table #browse data in a table format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a subset of the data points and features\n",
    "You will notice that there are multiple columns per collision and that not every collision has a related location. A more complex model may be able to incorporate this extra information but for now let's focus on just the locations of collisions and time of day. \n",
    "\n",
    "We filter the data: removing columns (features) and rows (collisions) so that we end up with a `numpy` array `X` of collisions with valid latitutes and longitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_collisions_table = collisions_table[np.isfinite(collisions_table['LATITUDE'])] #remove rows with NaNs\n",
    "loc_collisions_table['TIME_HOUR'] = loc_collisions_table.TIME.apply(lambda x: float(x.split(':')[0]) + float(x.split(':')[1])/60.)\n",
    "Xcol = loc_collisions_table.as_matrix(columns=['LONGITUDE','LATITUDE','TIME_HOUR'])\n",
    "Xcol #display the data as a N-by-4 numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the data\n",
    "It is good practice to standardize the data, that is, to transform the data such that it has zero mean and unit standard deviation. This helps with hyperparameter selection and parameter exploration. But sometimes it's useful to work in the original space, so be sure to save the transformation variables for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_mn = Xcol.mean(axis=0)\n",
    "tr_sd = (Xcol-tr_mn).std(axis=0)\n",
    "Xcol1 = (Xcol-tr_mn)/tr_sd\n",
    "#X = (X1-tr_mn)/tr_var\n",
    "print('transformation variables:\\n mean=',tr_mn,'std=',tr_sd)\n",
    "print('X=\\n',Xcol1)\n",
    "#check:\n",
    "print('check transformed X properties:\\n mean=',Xcol1.mean(axis=0),'std=',Xcol1.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "Now we are going to make a simple visualization of the data. Since `X` consists of 2-dimensional points we use a 2-dimensional scatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "ax = sns.lmplot(\"LONGITUDE\",\"LATITUDE\", data=loc_collisions_table, fit_reg=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 4\n",
    "\n",
    "Apply your *kmeans* implementation to the NYC collisions data. Visualize the results, including the cluster assignments. What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "mu3, R3 = kmeans(Xcol1,K)\n",
    "print('cluster centers',mu3)\n",
    "titles = ['%i data points, average time of day = %.1f hours' % (R3.sum(axis=0)[k], mu3[k,2]*tr_sd[2]+tr_mn[2]) for k in range(K)]\n",
    "plot_clusters_2D(Xcol1*tr_sd+tr_mn,R3,\n",
    "                 mu3*tr_sd+tr_mn,\n",
    "                 separate=True,titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
